import pyaudio
import numpy as np
import librosa
import tensorflow as tf
import time
import scipy.signal as signal

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
SAMPLE_RATE = 22050  # ‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á librosa
CHUNK = 1024       # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ö‡∏±‡∏ü‡πÄ‡∏ü‡∏≠‡∏£‡πå

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô
audio = pyaudio.PyAudio()
stream = audio.open(format=pyaudio.paFloat32, channels=1, rate=SAMPLE_RATE, 
                    input=True, frames_per_buffer=CHUNK)

def noise_gate(audio_data, threshold=0.02):
    """
    ‡πÉ‡∏ä‡πâ Noise Gate ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ threshold ‡∏≠‡∏≠‡∏Å
    """
    return np.where(np.abs(audio_data) >= threshold, audio_data, 0)

def bandpass_filter(audio_data, low_cutoff=90, high_cutoff=8000, sample_rate=22050, order=3):
    """
    ‡πÉ‡∏ä‡πâ Bandpass Filter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    """
    nyquist = 0.5 * sample_rate
    low = low_cutoff / nyquist
    high = high_cutoff / nyquist
    b, a = signal.butter(order, [low, high], btype='band')
    filtered_audio = signal.filtfilt(b, a, audio_data)
    return filtered_audio

def get_mel_from_audio():
    """
    ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡∏Ñ‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Mel spectrogram ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡πÅ‡∏•‡πâ‡∏ß
    ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö (silence) ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ None
    """
    try:
        audio_data = np.frombuffer(stream.read(CHUNK, exception_on_overflow=False), dtype=np.float32)
        
        # ‡πÉ‡∏ä‡πâ Noise Gate ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏ö‡∏≤
        gated_audio = noise_gate(audio_data, threshold=0.02)
        
        # ‡πÉ‡∏ä‡πâ Bandpass Filter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        filtered_audio = bandpass_filter(gated_audio, low_cutoff=90, high_cutoff=8000, sample_rate=SAMPLE_RATE, order=3)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô (RMS energy)
        energy = np.mean(np.abs(filtered_audio))
        silence_threshold = 0.005  # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ threshold ‡∏ï‡∏≤‡∏°‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
        if energy < silence_threshold:
            # ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö
            return None
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Mel spectrogram ‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏•‡∏î noise ‡πÅ‡∏•‡πâ‡∏ß
        mel = librosa.feature.melspectrogram(y=filtered_audio, sr=SAMPLE_RATE, n_mels=128, fmax=8000)
        return mel
    except Exception as e:
        print(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")
        return None

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Autopitch ‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÑ‡∏ß‡πâ
model = tf.keras.models.load_model("MelNoteClassifierV6.h5")  # ‡∏£‡∏∞‡∏ö‡∏∏ path ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

def midi_to_note(midi):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤ MIDI pitch ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ô‡πâ‡∏ï (‡πÄ‡∏ä‡πà‡∏ô C4, D#4)
    """
    note_names = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
    octave = midi // 12 - 1
    note = note_names[midi % 12]
    return f"{note}{octave}"

def predict_note():
    """
    ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡∏Ñ‡πå -> ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Mel spectrogram -> ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏ô‡πâ‡∏ï
    ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á (silence) ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ None
    """
    mel_input = get_mel_from_audio()
    if mel_input is None:
        return None  # ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ (‡πÄ‡∏á‡∏µ‡∏¢‡∏ö)
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö input shape ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (128, 128, 1)
    mel_input_resized = np.pad(mel_input, ((0, 0), (0, 128 - mel_input.shape[1])), 'constant')
    mel_input_resized = np.reshape(mel_input_resized, (1, 128, 128, 1))
    
    predicted = model.predict(mel_input_resized)
    predicted_midi = np.argmax(predicted)
    predicted_note_name = midi_to_note(predicted_midi)
    
    return predicted_note_name

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏ô‡πâ‡∏ï‡πÅ‡∏ö‡∏ö Real-time
print("üé§ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏ô‡πâ‡∏ï... (‡∏Å‡∏î Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î)")
try:
    while True:
        note_pred = predict_note()
        if note_pred is not None:
            print("üéµ Predicted Note:", note_pred)
        else:
            # ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            print("üîá Silence")
        time.sleep(0.5)
except KeyboardInterrupt:
    print("üî¥ ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
    stream.stop_stream()
    stream.close()
    audio.terminate()
